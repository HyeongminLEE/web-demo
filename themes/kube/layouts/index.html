{{ define "title"}} {{ .Site.Title}} {{end}}
{{ define "header"}} {{ partial "header" .}} {{end}}
{{ define "main"}}

<style>
    .small-title{
        color: royalblue;
        font-weight: 900;
        font-size: 45px;
        text-align: center;
    }
    #recent-update>li{
        font-size: 19px;
        margin-bottom: 15px;
    }
    #research-area>li{
        font-size: 30px;
        margin-bottom: 22px;
        font-weight: 500;
    }
    #teleport{
        text-decoration: none;
        color: #3794de;
        display: block;
        text-align: center;
        font-size: 22px;
        }
    #teleport:hover{
        text-decoration: none;
        font-weight: bold;
        color: #3794de;
        display: block;
        text-align: center;
        font-size: 22px;
        }
    #ra-link{
        text-decoration: none;
        color: #3794de;
        }
    #ra-link:hover{
        text-decoration: none;
        font-weight: 1000;
        color: #3794de;
        }
    #section-stats{
        padding-top: 40px;
        background-color: royalblue;
    }
    #section-stats > .small-title{
        color: white;
    }
    .stats{
        color: white !important;
        font-size: 30px !important;
        font-weight: 900;
    }
    .stats-title{
        color: white;
    }
    .contact{
        background-color: royalblue;
        padding-top: 80px;
        padding-bottom: 80px;
    }
    .contact .small-title{
        color: white;
    }
    #contact-content{
        color: white;
        font-size: 25px;
        text-align: center;
    }
    .tg-title{
        font-weight: 900;
        font-size: 23px;
        text-align: center;
    }
    .tg-content{
        height: 380px;
        text-align: center;
        font-size: 17px;
    }
    .tg:nth-child(1),.tg:nth-child(2){
        width: 33.3333333%;
        float: left;
    }
    .tg:nth-child(3){
        width: 33.3333333%;
    }
    @media all and (max-width: 768px){
        .tg:nth-child(1), .tg:nth-child(2), .tg:nth-child(3){
            display: block;
            width: 100%;
        }
        .tg-content{
            height: auto;
        }
    }
</style>


<div class="width-rsp" style="background-image: url(/general/2019_main.png); background-repeat: no-repeat; background-size: cover; background-position: center top; padding-bottom: 1px; width: 100%;">
      <div id="hero">
      <h1 style="color: white">{{.Title}}</h1>
      <p style="color: white">{{.Description}}</p>
      <div style="color: white; font-size: 20px;">School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea</div>
    </div>
    <div id="action-buttons">
      <a class="button primary big" href="/members" onclick="_gaq.push(['_trackEvent', 'kube', 'download']);">Our members</a>
    </div>
</div>

<div id="main" style="padding-left: 2rem; padding-right: 2rem;">

  <br/>
  <br/>
  <h2 class="small-title" style="margin-bottom: 30px; margin-top: 40px;">Recent Publications</h2>
  <ul id="recent-update">
    <li>
        M. Lee et al. <b>Guided Slot Attention for Unsupervised Video Object Segmentation</b>, <i>CVPR</i>, Jun 2024
      </li>
      <li>
        M. Lee, S. Cho et al. <b>Dual Prototype Attention for Unsupervised Video Object Segmentation</b>, <i>CVPR</i>, Jun 2024
      </li>
      <li>
        Y. Kim et al. <b>Efficient Image Compression through Differential Encoding of Super-Resolution Images</b>, <i>ICEIC</i>, Jan 2024
      </li>
      <li>
        D. Kang et al. <b>Enhancing Video Frame Interpolation With Flow-Guided Deformable Convolution</b>, <i>ICEIC</i>, Jan 2024
      </li>
      <li>
        M. Kang et al. <b>Real-time Semantic Segmentation with Bilateral Patch Attention</b>, <i>ICEIC</i>, Jan 2024
      </li>
      <li>
        M. Kang et al. <b>Monocular 3D Indoor Scene Reconstruction with Slot Attention</b>, <i>ICEIC</i>, Jan 2024
      </li>
      <li>
        M. Lee et al. <b>Boundary-aware Camouflaged Object Detection via Deformable Point Sampling</b>, <i>ICEIC</i>, Jan 2024
      </li>
      <li>
        M. Lee et al. <b>Referring Video Inpainting</b>, <i>ICEIC</i>, Jan 2024
      </li>
      <li>
        W. Lee et al. <b>MSV-RGNN: Multi-Scale Voxel Graph Neural Network for 3D Object Detection</b>, <i>ICIP</i>, Oct 2023
      </li>
      <li>
        Y. Lee et al. <b>Adaptive Graph Convolution Module for Salient Object Detection</b>, <i>ICIP</i>, Oct 2023
      </li>
      <li>
        S. Lee et al. <b>TSANET: Temporal and Scale Alignment for Unsupervised Video Object Segmentation</b>, <i>ICIP</i>, Oct 2023
      </li>
      <li>
        J. Lee et al. <b>Leveraging Spatio-Temporal Dependency for Skeleton-Based Action Recognition</b>, <i>ICCV</i>, Oct 2023
      </li>
      <li>
        J. Lee et al. <b>Hierarchically Decomposed Graph Convolutional Networks for Skeleton-Based Action Recognition</b>, <i>ICCV</i>, Oct 2023
      </li>
      <li>
        J. Lee et al. <b>Oneâ€‘Stage Mobile Palmprint Recognition via Keypoint Detection Network</b>, <i>ITC-CSCC</i>, Jun 2023
      </li>
      <li>
        S. Yim et al. <b>Object-Oriented Cutout Data Augmentation for Tiny Object Detection</b>, <i>ITC-CSCC</i>, Jun 2023
      </li>
    <li>
          S. Lee, H. Lee et al. <b>Exploring Discontinuity for Video Frame Interpolation</b>, <i>CVPR</i>, Jun 2023
    </li>
    <li>
          D. Lee et al. <b>DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors</b>, <i>CVPR</i>, Jun 2023
    </li>
    <li>
          M. Cho et al. <b>Look Around for Anomalies: Weakly-supervised Anomaly Detection via Context-Motion Relational Learning</b>, <i>CVPR</i>, Jun 2023
    </li>
    <li>
          D. Kim et al. <b>FAPM: Fast Adaptive Patch Memory for Real-time Industrial Anomaly Detection</b>, <i>ICASSP</i>, Jun 2023
    </li>
    <li>
          C. Park et al. <b>Two-stream Decoder Feature Normality Estimating Network for Industrial Anomaly Detection</b>, <i>ICASSP</i>, Jun 2023
    </li>
        <li>
          T. Kim et al. <b>Exploring Temporally Dynamic Data Augmentation for Video Recognition</b>, <i>ICLR</i>, May 2023
      </li>
        <li>
          S. Cho et al. <b>Tackling Background Distraction in Video Object Segmentation</b>, <i>ECCV</i>, Oct 2022
      </li>
        <li>
          C. Shin et al. <b>Expanded Adaptive Scaling Normalization for End to End Image Compression</b>, <i>ECCV</i>, Oct 2022
      </li>
        <li>
          M. Lee et al. <b>SPSN: Superpixel Prototype Sampling Network for RGB-D Salient Object Detection</b>, <i>ECCV</i>, Oct 2022
      </li>
        <li>
          S. Hwang et al. <b>LiDAR Depth Completion Using Color-Embedded Information via Knowledge Distillation</b>, <i>IEEE T-ITS</i>, Mar 2021
      </li>
       <li>
          W. Kim et al. <b>AIBM: Accurate and Instant Background Modeling for Moving Object Detection</b>, <i>IEEE T-ITS</i>, Jun 2021
      </li>
      <li>
          H. Bae et al. <b>Dog Nose-print Identification Using Deep Neural Networks</b>, <i>IEEE Access</i>, May 2021
      </li>
     <li>
          D. Lee et al. <b>Regularization Strategy for Point Cloud via Rigidly Mixed Sample</b>, <i>IEEE CVPR</i>, Jun 2021
      </li>
      <li>
          Our Lab ranked the 2nd Place in the <b>AIM 2020 Challenge on Image Extreme Inpainting</b> at ECCV 2020, Aug 2020 (C. Shin et al.)
      </li>
      <li>
          T. Kim, H.Lee, M.Cho et al. <b>Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition</b>, <i>ECCVW</i>, Aug 2020
      </li>
      <li>
          M. Cho et al. <b>Relational Deep Feature Learning for Heterogeneous Face Recognition</b>, <i>IEEE TIFS</i>, Jul 2020
      </li>
      <li>
          S. Cho et al. <b>CRVOS: Clue Refining Network for Video Object Segmentation</b>, <i>IEEE ICIP</i>, Oct 2020
      </li>
      <li>
          S. Woo et al. <b>False Positive Removal for 3D Vehicle Detection with Penetrated Point Classifier</b>, <i>IEEE ICIP</i>, Oct 2020
      </li>
      <li>
          S. Lee et al. <b>Extrapolative-Interpolative Cycle-Consistency Learning for Video Frame Extrapolation</b>, <i>IEEE ICIP</i>, Oct 2020
      </li>
      <li>
          Y. Ban et al. <b>Protuberance of depth: Detecting interest points from a depth image</b>, <i>CVIU</i>, May 2020
      </li>
      <li>
          H. Bae et al. <b>Non-Visual to Visual Translation for Cross-Domain Face Recognition</b>, <i>IEEE Access</i>, Mar 2020
      </li>
      <li>
          H. Lee et al. <b>AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation</b>, <i>IEEE CVPR</i>, Jun 2020
      </li>
  </ul>
   <br/>
    <div id="action-buttons">
      <a class="button primary big" href="/publications" onclick="_gaq.push(['_trackEvent', 'kube', 'download']);">More Publications</a>
    </div>
  
<br/>
<br/>

</div>

<div id="section-stats">
    <h2 class="small-title">Stats</h2>
    <div id="main">
        <div id="kube-features" style="margin-top: 30px !important;">
            <div class="row gutters">
              <div class="col col-3 item">
                <figure>
                  <img alt="Baseline" height="48" src="/icon/stats/papers.svg" width="48">
                </figure>
                <h3 class="stats-title">SCI(E) Papers</h3>
                <p class="count stats">57</p>
              </div>
              <div class="col col-3 item">
                <figure>
                  <img alt="Baseline" height="48" src="/icon/stats/project.svg" width="48">
                </figure>
                <h3 class="stats-title">Finished Projects</h3>
                <p class="count stats">118</p>
              </div>
              <div class="col col-3 item">
                <figure>
                  <img alt="Baseline" height="48" src="/icon/stats/patents.svg" width="48">
                </figure>
                <h3 class="stats-title">Patents</h3>
                <p class="count stats">86</p>
              </div>
              <div class="col col-3 item">
                <figure>
                  <img alt="Baseline" height="48" src="/icon/stats/graduate.svg" width="48">
                </figure>
                <h3 class="stats-title">Graduated Members</h3>
                <p class="count stats">30</p>
              </div>
            </div>
        </div>
    </div>
</div>

<br/>
<br/>
<br/>


<!--
<div class="research-area">
    <h2 class="small-title" style="margin-bottom: 70px;">Research Area</h2>
    <div id="main">
        <table class="tg">
          <tr>
            <td class="tg-img">img1</td>
            <td class="tg-img">img2</td>
            <td class="tg-img">img3</td>
          </tr>
          <tr>
            <td class="tg-title">Scene Understanding</td>
            <td class="tg-title">Human Analysis</td>
            <td class="tg-title">Image/Video Processing</td>
          </tr>
          <tr>
            <td class="tg-content">Scene Understanding consists of detection, tracking and recognition of the general objects in various environment.<br><br>By understanding the spatiotemporal and semantic relationship in between the objects, object and scene can be modeled and reconstructed in 3D.<br><br>Based on the understanding of the scene and the object, our researches can be applied to real-time applications such as Autonomous Driving and Surveillance systems.</td>
            <td class="tg-content">Human Analysis is to detect, track and recognize the features by analyzing the action and behavior of the people including face, hands and the entire body.<br><br>Based on these recognition and detection, the extracted features can be utilized for landmark and pose estimation and gesture recognition,Furthermore, human behavior can be restored from analyzing the emotions.<br><br>Our researches of the Human Analysis can be applied to various applications such as Human-Computer and Human-Mobile Device Interaction.</td>
            <td class="tg-content">Image/Video Processing analyzes the low-level features of the multimedia.<br><br>It plays an important role for Scene Understanding and Human Analysis, by taking pre-processing and post processing.<br><br>From analyzing the correlation of the images, having various modality, it enhances and restores the images.<br><br>Our researches of the Image/Video Processing are applied to Image Enhancement and Video Coding/Streaming.</td>
          </tr>
        </table>
    </div>
</div>
-->
<!-- <div class="research-area">
    <h2 class="small-title" style="margin-bottom: 70px;">Research Area</h2>
    <div id="main">
        <table class="tg">
            <tr><td class="tg-img"></td></tr>
            <tr><td class="tg-title">Scene Understanding</td></tr>
            <tr><td class="tg-content">Scene Understanding consists of detection, tracking and recognition of the general objects in various environment.<br><br>By understanding the spatiotemporal and semantic relationship in between the objects, object and scene can be modeled and reconstructed in 3D.<br><br>Based on the understanding of the scene and the object, our researches can be applied to real-time applications such as Autonomous Driving and Surveillance systems.</td></tr>
        </table>
        <table class="tg">
            <tr><td class="tg-img"></td></tr>
            <tr><td class="tg-title">Human Analysis</td></tr>
            <tr><td class="tg-content">Human Analysis is to detect, track and recognize the features by analyzing the action and behavior of the people including face, hands and the entire body.<br><br>Based on these recognition and detection, the extracted features can be utilized for landmark and pose estimation and gesture recognition,Furthermore, human behavior can be restored from analyzing the emotions.<br><br>Our researches of the Human Analysis can be applied to various applications such as Human-Computer and Human-Mobile Device Interaction.</td></tr>
        </table>
        <table class="tg">
            <tr><td class="tg-img"></td></tr>
            <tr><td class="tg-title">Image/Video Processing</td></tr>
            <tr><td class="tg-content">Image/Video Processing analyzes the low-level features of the multimedia.<br><br>It plays an important role for Scene Understanding and Human Analysis, by taking pre-processing and post processing.<br><br>From analyzing the correlation of the images, having various modality, it enhances and restores the images.<br><br>Our researches of the Image/Video Processing are applied to Image Enhancement and Video Coding/Streaming.</td></tr>
        </table>
    </div>
    <br/>
    <div id="action-buttons" style="margin-bottom: 0">
      <a class="button primary big" href="/research" onclick="_gaq.push(['_trackEvent', 'kube', 'download']);">About More...</a>
    </div>
</div> -->
 
<!--  <br/>
 <br/>
 <br/>
 <br/> -->
  
<div class="contact">
    <div id="main">
      <h2 class="small-title">Contact Us</h2>
      <br/>
      <br/>
    <div id="action-buttons" style="margin-bottom: 0">
      <a class="button primary big" href="/contact" onclick="_gaq.push(['_trackEvent', 'kube', 'download']);">About More...</a>
    </div>
    </div>
</div>  
  


<script>
    $('.count').each(function () {
        $(this).prop('Counter',0).animate({
            Counter: $(this).text()
        }, {
            duration: 2200,
            easing: 'swing',
            step: function (now) {
                $(this).text(Math.ceil(now));
            }
        });
    });
</script>

{{ end }}
{{ define "footer"}} {{ partial "footer" .}} {{end}}
